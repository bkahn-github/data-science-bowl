{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_multioutput_unet.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "3rEYueMrsSdR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "!rm -rf *\n",
        "!rm -rf .kaggle/\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "f = open(\".kaggle/kaggle.json\", \"w\")\n",
        "f.write('{\"username\":\"bkkaggle\",\"key\":\"bf4e62680116284087ace0484990f87a\"}')\n",
        "f.close()\n",
        "\n",
        "!git clone https://github.com/bkahn-github/data-science-bowl.git\n",
        "os.chdir('data-science-bowl/pytorchMultiOutputUnet/')\n",
        "!git checkout multioutput-unet\n",
        "!pip install -r ../requirements.txt\n",
        "\n",
        "!kaggle competitions download -c data-science-bowl-2018\n",
        "!unzip -q ~/.kaggle/competitions/data-science-bowl-2018/stage1_train.zip -d ~/.kaggle/competitions/data-science-bowl-2018/stage1_train\n",
        "!unzip -q ~/.kaggle/competitions/data-science-bowl-2018/stage1_test.zip -d ~/.kaggle/competitions/data-science-bowl-2018/stage1_test\n",
        "!unzip -q ~/.kaggle/competitions/data-science-bowl-2018/stage1_train_labels.csv.zip -d ~/.kaggle/competitions/data-science-bowl-2018/\n",
        "!unzip -q ~/.kaggle/competitions/data-science-bowl-2018/stage1_sample_submission.csv.zip -d ~/.kaggle/competitions/data-science-bowl-2018/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KYOqahC7me3b",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "file_id = '1MU9EsOl0wSHzjLiolUzuLLMQHiN_YNgu'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('model-20.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ZGw9ujqs6Lp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!python main.py --subset=True preprocess"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i6fJV6whOg49",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!python main.py --subset=False train --epochs=20 --patience=5 --kfolds=1 --batchSize=2 --weights='model-20.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1pOaG5tv1Bs1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from config import config\n",
        "from main import visualize\n",
        "\n",
        "config.SUBSET = True\n",
        "config.AUGMENT = False\n",
        "\n",
        "visualize('model-20.pt')\n",
        "# visualize('model-kfold-0-best.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jPA_m7gzx20a",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "from config import config\n",
        "from loaders import TrainDataset, augmentation\n",
        "from model import Unet\n",
        "from utils import get_kfolds\n",
        "\n",
        "def postprocess(weights):\n",
        "    model = Unet()\n",
        "\n",
        "    model.load_state_dict(torch.load(weights, map_location=lambda storage, location: storage))\n",
        "    model.eval()\n",
        "\n",
        "    model.cuda()\n",
        "  \n",
        "    kfolds = get_kfolds(2)\n",
        "  \n",
        "    dataset = TrainDataset(kfolds[0][0], augmentation=augmentation)\n",
        "    dataLoader = DataLoader(dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=config.NUM_WORKERS)\n",
        "\n",
        "    for data in dataLoader:\n",
        "        img, target = data['img'], data['mask']\n",
        "\n",
        "        x = Variable(img).cuda()\n",
        "        y = Variable(target).cuda()\n",
        "\n",
        "        outs = model(x)\n",
        "        break\n",
        "\n",
        "    x = x.data.cpu().numpy()\n",
        "    y = y.data.cpu().numpy()\n",
        "    outs = outs.data.cpu().numpy()\n",
        "\n",
        "    return x, y, outs\n",
        "  \n",
        "x, y, outs = postprocess('model-20.pt')\n",
        "# x, y, outs = postprocess('model-kfold-0-best.pt')\n",
        "\n",
        "# from skimage.morphology import label, binary_dilation, erosion, binary_closing\n",
        "# from skimage.segmentation import random_walker\n",
        "\n",
        "# # outs[0][1] *= (255.0/outs[0][1].max())\n",
        "\n",
        "# mask = outs[0,0]\n",
        "# contour = outs[0,1]\n",
        "    \n",
        "# mask = (mask*255).astype(np.uint8)\n",
        "# contour = (contour*255).astype(np.uint8)\n",
        "\n",
        "# _, mask = cv2.threshold(mask, 0, 255, cv2.THRESH_OTSU)\n",
        "# _, contour = cv2.threshold(contour, 0, 255, cv2.THRESH_OTSU)\n",
        "\n",
        "# sure_foreground = (contour - mask)\n",
        "# sure_background = erosion(mask)\n",
        "\n",
        "# mask_plus_contour = cv2.add(mask, contour)\n",
        "# mask_plus_contour = cv2.cvtColor(mask_plus_contour, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "# unknown = cv2.subtract(sure_background, sure_foreground)\n",
        "\n",
        "# # Marker labelling\n",
        "# output = cv2.connectedComponentsWithStats(sure_foreground)\n",
        "# labels = output[1]\n",
        "# stats = output[2]\n",
        "# # Add one to all labels so that sure background is not 0, 0 is considered unknown by watershed\n",
        "# # this way, watershed can distinguish unknown from the background\n",
        "# labels = labels + 1\n",
        "# labels[unknown==255] = 0\n",
        "\n",
        "# labels = cv2.watershed(mask_plus_contour, labels)\n",
        "# # labels = random_walker(mask_plus_contour, labels, multichannel=True)   \n",
        "\n",
        "# labels[labels==-1] = 0\n",
        "# labels[labels==1] = 0\n",
        "# labels = labels -1\n",
        "# labels[labels==-1] = 0\n",
        "\n",
        "# mean = np.mean(stats[1:,cv2.CC_STAT_AREA])\n",
        "\n",
        "# for i in range(1, labels.max()):\n",
        "#      if stats[i, cv2.CC_STAT_AREA] > mean*10 or stats[i, cv2.CC_STAT_AREA] < mean/10:\n",
        "#         labels[labels==i] = 0\n",
        "\n",
        "        \n",
        "# def renumber_labels(label_img):\n",
        "#     \"\"\" Re-number nuclei in a labeled image so the nuclei numbers are unique and consecutive.\n",
        "#     \"\"\"\n",
        "#     new_label = 0\n",
        "#     for old_label in np.unique(label_img):\n",
        "#         if not old_label == new_label:\n",
        "#             label_img[label_img == old_label] = new_label\n",
        "            \n",
        "#         new_label += 1\n",
        "  \n",
        "#     return label_img\n",
        "\n",
        "# labels = renumber_labels(labels)\n",
        "img = np.concatenate((outs[0][0:1].reshape(256, 256, 1), outs[0][1:2].reshape(256, 256, 1), (outs[0][2]).reshape(256, 256, 1)), axis=-1).reshape(256, 256, 3)\n",
        "truth = np.concatenate((y[0][0:1].reshape(256, 256, 1), y[0][1:2].reshape(256, 256, 1), (y[0][2] > 0).astype(np.uint8).reshape(256, 256, 1)), axis=-1).reshape(256, 256, 3)\n",
        "x = np.concatenate((x[0][0:1].reshape(256, 256, 1), x[0][1:2].reshape(256, 256, 1), (x[0][2]).reshape(256, 256, 1)), axis=-1).reshape(256, 256, 3)\n",
        "\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HkoKinCMajjt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "img[:,:,1] = img[:,:,1]*10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t0pGS3_Tv_c5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(img[:,:,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "35PlLv-oX5gW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "from config import config\n",
        "from loaders import TrainDataset, augmentation\n",
        "from model import Unet\n",
        "from utils import get_kfolds\n",
        "\n",
        "config.SUBSET = False\n",
        "\n",
        "def postprocess(weights):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(device)\n",
        "    model = Unet()\n",
        "\n",
        "    model.load_state_dict(torch.load(weights, map_location=lambda storage, location: storage))\n",
        "    model.eval()\n",
        "\n",
        "    model.to(device)\n",
        "  \n",
        "    kfolds = get_kfolds(2)\n",
        "  \n",
        "    dataset = TrainDataset(kfolds[0][0], augmentation=augmentation)\n",
        "    dataLoader = DataLoader(dataset, batch_size=config.BATCH_SIZE, shuffle=config.SHUFFLE, num_workers=config.NUM_WORKERS)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in dataLoader:\n",
        "            img, target = data['img'], data['target']\n",
        "\n",
        "            x = Variable(img).to(device)\n",
        "            y = Variable(target).to(device)\n",
        "\n",
        "            outs = model(x)\n",
        "            break\n",
        "\n",
        "    x = x.detach().cpu().numpy()\n",
        "    y = y.detach().cpu().numpy()\n",
        "    outs = outs.detach().cpu().numpy()\n",
        "    \n",
        "    return x, y, outs\n",
        "  \n",
        "x, y, outs = postprocess('model-20.pt')\n",
        "# x, y, outs = postprocess('model-kfold-0-best.pt')\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.morphology import label, binary_dilation, erosion, binary_closing\n",
        "from skimage.segmentation import random_walker\n",
        "\n",
        "\n",
        "# outs[0][1] *= (255.0/outs[0][1].max())\n",
        "\n",
        "mask = outs[0,0]\n",
        "contour = outs[0,1]\n",
        "    \n",
        "mask = (mask*255).astype(np.uint8)\n",
        "contour = (contour*255).astype(np.uint8)\n",
        "\n",
        "_, mask = cv2.threshold(mask, 0, 255, cv2.THRESH_OTSU)\n",
        "_, contour = cv2.threshold(contour, 0, 255, cv2.THRESH_OTSU)\n",
        "\n",
        "sure_foreground = (contour - mask)\n",
        "sure_background = erosion(mask)\n",
        "\n",
        "mask_plus_contour = cv2.add(mask, contour)\n",
        "mask_plus_contour = cv2.cvtColor(mask_plus_contour, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "unknown = cv2.subtract(sure_background, sure_foreground)\n",
        "\n",
        "# Marker labelling\n",
        "output = cv2.connectedComponentsWithStats(sure_foreground)\n",
        "labels = output[1]\n",
        "stats = output[2]\n",
        "# Add one to all labels so that sure background is not 0, 0 is considered unknown by watershed\n",
        "# this way, watershed can distinguish unknown from the background\n",
        "labels = labels + 1\n",
        "labels[unknown==255] = 0\n",
        "plt.imshow(labels)\n",
        "\n",
        "labels = cv2.watershed(mask_plus_contour, labels)\n",
        "# labels = random_walker(mask_plus_contour, labels, multichannel=True)   \n",
        "\n",
        "labels[labels==-1] = 0\n",
        "labels[labels==1] = 0\n",
        "labels = labels -1\n",
        "labels[labels==-1] = 0\n",
        "\n",
        "mean = np.mean(stats[1:,cv2.CC_STAT_AREA])\n",
        "\n",
        "for i in range(1, labels.max()):\n",
        "     if stats[i, cv2.CC_STAT_AREA] > mean*10 or stats[i, cv2.CC_STAT_AREA] < mean/10:\n",
        "        labels[labels==i] = 0\n",
        "\n",
        "        \n",
        "def renumber_labels(label_img):\n",
        "    \"\"\" Re-number nuclei in a labeled image so the nuclei numbers are unique and consecutive.\n",
        "    \"\"\"\n",
        "    new_label = 0\n",
        "    for old_label in np.unique(label_img):\n",
        "        if not old_label == new_label:\n",
        "            label_img[label_img == old_label] = new_label\n",
        "        new_label += 1\n",
        "  \n",
        "    return label_img\n",
        "        \n",
        "labels = renumber_labels(labels)\n",
        "\n",
        "plt.imshow(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qwV63USs3IW1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "img = np.concatenate((outs[0][0:1].reshape(256, 256, 1), outs[0][1:2].reshape(256, 256, 1), (outs[0][2]).reshape(256, 256, 1)), axis=-1).reshape(256, 256, 3)\n",
        "truth = np.concatenate((y[0][0:1].reshape(256, 256, 1), y[0][1:2].reshape(256, 256, 1), (y[0][2] > 0).astype(np.uint8).reshape(256, 256, 1)), axis=-1).reshape(256, 256, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k_8YD_BDgJLt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(img[:,:,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uuroh9N6gJVn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(img[:,:,0] - img[:,:,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O0y1fxTlgJf1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(truth[:,:,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZN0w_3tUgT9j",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "img[:,:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gILM9R7qmKcF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'pytorch-multioutput-unet-40-epochs-version-23'})\n",
        "uploaded.SetContentFile('model-kfold-0-best.pt')\n",
        "\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wCcnJCUGN8yC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, pooling=True):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.pooling = pooling\n",
        "      \n",
        "        self.conv = nn.Sequential(\n",
        "          nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "          nn.BatchNorm2d(out_ch),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Dropout2d(0.2),\n",
        "          nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "          nn.BatchNorm2d(out_ch),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Dropout2d(0.2)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)      \n",
        "  \n",
        "        if self.pooling == True:\n",
        "            x = F.max_pool2d(x, 2)\n",
        "                            \n",
        "        return x\n",
        "\n",
        "class Upsample(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(Upsample, self).__init__()\n",
        "\n",
        "        self.upsample = nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2)\n",
        "        self.conv = ConvBlock(in_ch, out_ch, pooling=False)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        upsample = self.upsample(x1)\n",
        "        \n",
        "        cat = torch.cat([x2, upsample], dim=1)\n",
        "        conv = self.conv(cat)\n",
        "\n",
        "        return conv\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(OutConv, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = F.sigmoid(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Unet2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Unet2, self).__init__()\n",
        "\n",
        "        self.in_conv = ConvBlock(3, 64, pooling=False)\n",
        "        self.down_1 = ConvBlock(64, 128)\n",
        "        self.down_2 = ConvBlock(128, 256)\n",
        "        self.down_3 = ConvBlock(256, 512)\n",
        "        self.down_4 = ConvBlock(512, 1024)\n",
        "        self.up_1 = Upsample(1024, 512)\n",
        "        self.up_2 = Upsample(512, 256)\n",
        "        self.up_3 = Upsample(256, 128)\n",
        "        self.up_4 = Upsample(128, 64)\n",
        "        \n",
        "        self.out_conv = OutConv(64, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x / 255\n",
        "    \n",
        "        x1 = self.in_conv(x)\n",
        "        x2 = self.down_1(x1)\n",
        "        x3 = self.down_2(x2)\n",
        "        x4 = self.down_3(x3)\n",
        "        x5 = self.down_4(x4)\n",
        "        x = self.up_1(x5, x4)\n",
        "        x = self.up_2(x, x3)\n",
        "        x = self.up_3(x, x2)\n",
        "        x = self.up_4(x, x1)\n",
        "        \n",
        "        outputs = self.out_conv(x)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NXucZX_iOEai",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from config import config\n",
        "from create_masks import create_masks\n",
        "from loaders import TrainDataset, x_transforms, target_transforms\n",
        "from model import Unet\n",
        "from visualize import show_images\n",
        "# from metrics import loss\n",
        "from utils import get_kfolds, calculate_losses, calculate_kfolds_losses, save_model, load_model, EarlyStopping\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "\n",
        "def loss(inputs, targets):  \n",
        "  epsilon = 1e-5\n",
        "  inputs = torch.clamp(inputs.cpu(), epsilon, 1. - epsilon)\n",
        "  weight = 30 * targets[:,0:1].cpu() + 3 * targets[:,1:2].cpu() + 1 * targets[:,2:3].cpu()\n",
        "  \n",
        "  loss = - torch.sum(target.cpu() * weight.cpu() * torch.log(inputs.cpu()) + (1 - targets.cpu()) * torch.log(1 - inputs.cpu()), 1)\n",
        "#   print(loss)\n",
        "  \n",
        "  return loss\n",
        "  \n",
        "config.SUBSET = True\n",
        "\n",
        "epochs = 10\n",
        "weights = ''\n",
        "kfolds = 1\n",
        "\n",
        "kfolds = get_kfolds(kfolds)\n",
        "\n",
        "if weights != '':\n",
        "    model = Unet()\n",
        "    model = load_model(model, weights)\n",
        "\n",
        "total_kfolds_train_loss = 0\n",
        "total_kfolds_val_loss = 0\n",
        "\n",
        "for i, kfold in enumerate(kfolds):\n",
        "    print('\\n')\n",
        "    logging.info('=' * 50)\n",
        "    logging.info('Kfold # ' + str(i + 1))\n",
        "\n",
        "    train_ids, val_ids = kfold[0], kfold[1]\n",
        "\n",
        "    logging.info('Creating Dataset')\n",
        "    train = TrainDataset(train_ids, x_transform=x_transforms, target_transforms=target_transforms)\n",
        "    trainDataloader = DataLoader(train, batch_size=config.BATCH_SIZE, shuffle=config.SHUFFLE, num_workers=config.NUM_WORKERS)\n",
        "    val = TrainDataset(val_ids, x_transform=x_transforms, target_transforms=target_transforms)\n",
        "    valDataloader = DataLoader(val, batch_size=config.BATCH_SIZE, shuffle=config.SHUFFLE, num_workers=config.NUM_WORKERS)\n",
        "\n",
        "    if weights != '' and i == 0:\n",
        "        model = model\n",
        "        weights = ''\n",
        "    else:\n",
        "        model = Unet()\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=config.LR, momentum=0.9)\n",
        "\n",
        "    early_stopping = EarlyStopping()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch += 1\n",
        "        print('\\n')\n",
        "        logging.info('-' * 50)\n",
        "        logging.info('Epoch # ' + str(epoch))\n",
        "\n",
        "        total_train_loss = 0\n",
        "        for data in tqdm(trainDataloader):\n",
        "            img, target = data['img'], data['target']\n",
        "\n",
        "            x = img.requires_grad_().to(device)\n",
        "            y = target.requires_grad_().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outs = model(x)\n",
        "            train_loss = loss(outs, y)\n",
        "            \n",
        "            train_loss.backward(gradient=train_loss)\n",
        "            total_train_loss += (torch.sum(train_loss.view(-1)) / len(train_loss.view(-1))).item()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data in tqdm(valDataloader):\n",
        "                img, target = data['img'], data['target']\n",
        "\n",
        "                x = img.to(device)\n",
        "                y = target.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outs = model(x)\n",
        "                val_loss = loss(outs, y)\n",
        "                total_val_loss += (torch.sum(val_loss.view(-1)) / len(val_loss.view(-1))).item()\n",
        "\n",
        "        message, train_loss, val_loss = calculate_losses(total_train_loss, total_val_loss, train_ids, val_ids, epoch)\n",
        "        print(message)\n",
        "\n",
        "        total_kfolds_train_loss += train_loss\n",
        "        total_kfolds_val_loss += val_loss\n",
        "\n",
        "        action = early_stopping.evaluate(model, val_loss, epoch, config.PATIENCE)\n",
        "\n",
        "        if action == 'save':\n",
        "            save_model(model, i)\n",
        "        elif action == 'stop':\n",
        "            break\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "message = calculate_kfolds_losses(total_kfolds_train_loss, total_kfolds_val_loss, config.KFOLDS, config.EPOCHS)\n",
        "print(message)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "51Nc_Ah_mM9R",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# !ls\n",
        "os.chdir('./pytorchMultiOutputUnet/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tGDn62KT7gvA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# (torch.sum(temp.view(-1)) / len(temp.view(-1))).item()\n",
        "train_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EV_29ZeWSXuZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "weights = 'model-kfold-0-best.pt'\n",
        "\n",
        "model = Unet()\n",
        "model.load_state_dict(torch.load(weights))\n",
        "model.eval()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "kfolds = get_kfolds(2)\n",
        "\n",
        "dataset = TrainDataset(kfolds[0][0], x_transform=x_transforms, target_transforms=target_transforms)\n",
        "dataLoader = DataLoader(dataset, batch_size=config.BATCH_SIZE, shuffle=config.SHUFFLE, num_workers=config.NUM_WORKERS)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in dataLoader:\n",
        "        img, target = data['img'], data['target']\n",
        "\n",
        "        x = Variable(img).to(device)\n",
        "        y = Variable(target).to(device)\n",
        "\n",
        "        outs = model(x)\n",
        "        break\n",
        "\n",
        "y = y.detach().cpu().numpy()\n",
        "outs = outs.detach().cpu().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JeIXJ3BrSgxd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(outs[0].reshape(256, 256, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dNG_Z-cPVEtt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from imageio import imwrite\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from scipy import ndimage\n",
        "import skimage.morphology\n",
        "from config import config\n",
        "\n",
        "def get_edges(img):\n",
        "    img = skimage.morphology.binary_dilation(img, selem=np.ones((5,5))).astype(np.uint8)\n",
        "    return img\n",
        "  \n",
        "def get_sizes(mask_folder):\n",
        "    mask = glob.glob(os.path.join(mask_folder, 'masks/*'))[0]\n",
        "    img = Image.open(mask)\n",
        "    img = np.asarray(img)\n",
        "\n",
        "    return img.shape\n",
        "\n",
        "def create_masks(root_folder, stage_number, stage_section, output_folder, mode, subset=False):\n",
        "    stage_folder = os.path.join(root_folder, 'stage' + stage_number + '_' + stage_section) \n",
        "    os.makedirs(stage_folder + '_' + mode, exist_ok=True)\n",
        "\n",
        "    if subset:\n",
        "        masks_folder = glob.glob(os.path.join(stage_folder, '*'))[:20]\n",
        "    else:\n",
        "        masks_folder = glob.glob(os.path.join(stage_folder, '*'))        \n",
        "    \n",
        "    for mask_folder in tqdm(masks_folder):\n",
        "        mask_id = mask_folder.split('/')[-1]\n",
        "\n",
        "        size = get_sizes(mask_folder)\n",
        "        \n",
        "        masks = np.zeros(size)\n",
        "        masks_with_edges = np.zeros(size)\n",
        "\n",
        "        for mask in glob.glob(os.path.join(mask_folder, 'masks/*')):\n",
        "            img = Image.open(mask)\n",
        "            img = np.asarray(img)\n",
        "            img = img / 255.0\n",
        "\n",
        "            img_with_edges = get_edges(img)\n",
        "            \n",
        "            masks = np.add(masks, img)\n",
        "            masks_with_edges = np.add(masks_with_edges, img_with_edges)\n",
        "\n",
        "        target = np.zeros((size[0], size[1], 3))\n",
        "        \n",
        "        target[:,:,0] = masks == 1\n",
        "        target[:,:,1] = masks_with_edges == 2\n",
        "        target[:,:,2] = masks == 0\n",
        "        \n",
        "        target *= 255\n",
        "        target = target.astype(np.uint8)\n",
        "\n",
        "#         return target\n",
        "        output_path = os.path.join(stage_folder + '_' + mode, mask_id + '.png')        \n",
        "        imwrite(output_path, target)\n",
        "        \n",
        "test = create_masks(config.ROOT_FOLDER, config.STAGE, 'train', config.TARGETS_FOLDER, 'masks', config.SUBSET)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rBaX-Tkoda2x",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(test[:,:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ywpXCDchyXLx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(test[:,:,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k1cOmJNzmQSg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}